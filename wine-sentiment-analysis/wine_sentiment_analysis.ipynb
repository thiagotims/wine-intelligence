{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",

  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† An√°lise de Sentimentos com BERTimbau em Coment√°rios de Vinho"
      ],
      "metadata": {
        "id": "5LIUIoGnICG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lise de Sentimento usando BERTimbau para textos em portugu√™s\n",
        "\n",
        "Dataset: 350 linhas com coment√°rios sobre vinho (200 rotuladas)"
      ],
      "metadata": {
        "id": "yBs8wYDuXq6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala√ß√£o das bibliotecas necess√°rias\n",
        "!pip install transformers pandas numpy scikit-learn torch\n",
        "\n",
        "# Importando as bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92q_JXB3BKzn",
        "outputId": "1da05612-f4fa-4f8f-9a30-c36bbe9f6ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se GPU est√° dispon√≠vel\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VgoiZJB1_g",
        "outputId": "01cee2bf-523e-4ff1-c155-98dbea49d49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "try:\n",
        "    # Tente carregar seu dataset real\n",
        "    df = pd.read_csv('/content/drive/MyDrive/datasets/avaliacoes_caminhos_merlot_2023.csv')\n",
        "    print(\"Dataset carregado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"Dataset n√£o carregado! Erro: {e}\")"
      ],
      "metadata": {
        "id": "4xMpnqH8IPok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d4728d-2077-4b1a-fa60-6018a25a2106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar estat√≠sticas do dataset\n",
        "print(\"\\nInforma√ß√µes do Dataset:\")\n",
        "print(f\"Total de registros: {len(df)}\")\n",
        "print(f\"Registros rotulados: {df['sentimento'].notna().sum()}\")\n",
        "print(f\"Registros n√£o rotulados: {df['sentimento'].isna().sum()}\")\n",
        "\n",
        "# Exibir distribui√ß√£o de sentimentos nos dados rotulados\n",
        "if df['sentimento'].notna().sum() > 0:\n",
        "    sentimentos = df[df['sentimento'].notna()]['sentimento'].value_counts()\n",
        "    print(\"\\nDistribui√ß√£o de sentimentos:\")\n",
        "    print(f\"Negativos: {sentimentos.get(0, 0)}\")\n",
        "    print(f\"Neutros: {sentimentos.get(1, 0)}\")\n",
        "    print(f\"Positivos: {sentimentos.get(2, 0)}\")\n",
        "\n",
        "# Exibir alguns exemplos\n",
        "print(\"\\nExemplos do dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "d7yKo1bNIPlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c12dbf-a9a0-453c-e301-a20b991c0955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informa√ß√µes do Dataset:\n",
            "Total de registros: 350\n",
            "Registros rotulados: 200\n",
            "Registros n√£o rotulados: 150\n",
            "\n",
            "Distribui√ß√£o de sentimentos:\n",
            "Negativos: 60\n",
            "Neutros: 70\n",
            "Positivos: 70\n",
            "\n",
            "Exemplos do dataset:\n",
            "       nome                                         comentario  sentimento\n",
            "0   Juliana     Final amargo e desconfort√°vel, n√£o recomendo.          0.0\n",
            "1   Roberto  Um Merlot honesto, dentro do esperado para a s...         NaN\n",
            "2     Pedro  Simplesmente adorei! Vinho que transmite quali...         NaN\n",
            "3  Fernanda  Aromas complexos e um paladar refinado. Caminh...         NaN\n",
            "4       Bia  Infelizmente achei o Caminhos Merlot 2023 muit...         0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©-processamento\n",
        "def limpar_texto(texto):\n",
        "    \"\"\"Fun√ß√£o para limpar e normalizar o texto\"\"\"\n",
        "    if isinstance(texto, str):\n",
        "        # Converter para min√∫sculas\n",
        "        texto = texto.lower()\n",
        "        # Remover caracteres especiais, manter acentos\n",
        "        texto = re.sub(r'[^\\w\\s\\d√°√†√¢√£√©√®√™√≠√¨√Æ√≥√≤√¥√µ√∫√π√ª√ß√±]', '', texto)\n",
        "        # Remover espa√ßos extras\n",
        "        texto = re.sub(r'\\s+', ' ', texto)\n",
        "        return texto.strip()\n",
        "    return \"\"\n",
        "\n",
        "# Aplicar limpeza ao dataset completo\n",
        "df['comentario_processado'] = df['comentario'].apply(limpar_texto)"
      ],
      "metadata": {
        "id": "qlIs2FiHIPik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar dados rotulados e n√£o rotulados\n",
        "df_rotulado = df[df['sentimento'].notna()].copy()\n",
        "df_rotulado['sentimento'] = df_rotulado['sentimento'].astype(int)\n",
        "df_nao_rotulado = df[df['sentimento'].isna()].copy()"
      ],
      "metadata": {
        "id": "Hp9VdHj9IPfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe personalizada para o dataset PyTorch\n",
        "class ComentariosDataset(Dataset):\n",
        "    def __init__(self, comentarios, sentimentos, tokenizer, max_len=128):\n",
        "        self.comentarios = comentarios\n",
        "        self.sentimentos = sentimentos\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comentarios)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        comentario = self.comentarios[idx]\n",
        "\n",
        "        # Tokenizar o texto\n",
        "        encoding = self.tokenizer(\n",
        "            comentario,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Converter para tensores e retornar\n",
        "        input_ids = encoding['input_ids'].flatten()\n",
        "        attention_mask = encoding['attention_mask'].flatten()\n",
        "\n",
        "        if self.sentimentos is not None:\n",
        "            sentimento = torch.tensor(self.sentimentos[idx], dtype=torch.long)\n",
        "            return {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask,\n",
        "                'sentimento': sentimento\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask\n",
        "            }\n"
      ],
      "metadata": {
        "id": "3EIV4IEVIPc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de classifica√ß√£o baseado no BERTimbau\n",
        "class SentimentoClassificador(torch.nn.Module):\n",
        "    def __init__(self, bert_model, num_classes=3):\n",
        "        super(SentimentoClassificador, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "M7WbwT1tIPaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o tokenizador e modelo BERTimbau\n",
        "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
        "print(f\"\\nCarregando modelo: {model_name}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Divis√£o dos dados rotulados em treino e valida√ß√£o\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_rotulado['comentario_processado'].values,\n",
        "    df_rotulado['sentimento'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_rotulado['sentimento'].values\n",
        ")\n",
        "\n",
        "print(f\"\\nDados de treinamento: {len(train_texts)}\")\n",
        "print(f\"Dados de valida√ß√£o: {len(val_texts)}\")"
      ],
      "metadata": {
        "id": "YVlY7BezIPXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "6c9d5e0d68b540c6bc6439d7c15d9d85",
            "32dcd6abbf1c4bf992e1f7602dfa6516",
            "e09674d3ed824eea8eb411a1b9790bcb",
            "af08cf88ef96487da8fbaae03fe1df26",
            "a59dd191111c4a19ae6efeed2d030553",
            "df8f948dad9c42f69a2e128252d99397",
            "bd0c5bd422da46f8a1b877f44834675e",
            "7a2a5df4fcf945b588500f7c26ea0f80",
            "faf31186d86e4e12895cb6a1398a3b8d",
            "3cb8733e52d54612a36b8b821cf59f09",
            "91936f0ae9f547c8a49c3eb8e23a9a4f",
            "ea99a78afa89473aa3f07914bc6c15ea",
            "d5a347c1bbc24f41b5b78d37959b4635",
            "d6e536a0bf36431fa7f6c84c456736d7",
            "26d737b59c054a49b8f46ca6a1c63051",
            "3a50e1ef150242e8a04c09d039e196a5",
            "cc247367b16c4507a08d47476bd9e641",
            "26aa5038966b408d9e47707fc5db4a5e",
            "b16c42b3467b4349a3343d4793110847",
            "553cb6b222e24866be781eedce13afca",
            "958f0aabcea644899c93767898fcfceb",
            "8332772143fa4ad1af01eaeb8ff171eb",
            "ef044e7d7641462f86d64d3f6a1edca1",
            "9387554aa1c84b11937c7379e352da28",
            "d278f8741aa4400f8a12346d298cc50a",
            "8358a9aa26c94515b7af6a269a8147a4",
            "c1a52c9bb1d0413e82601937d728afaa",
            "7b0da143ed3e4ebab62b6cfc577d8fbd",
            "cc861bea7c3e4fb18d5359ff9fb60915",
            "1747983b4d1e4870898b3ec69b8d3d07",
            "4f9c57b1c9e64bd79a86e0dcdf392717",
            "1dc315579a274fef8db95aec18f580dd",
            "c74e46dba06e499691c090adf5b222ea",
            "d8372d10e215430db6281169984a5034",
            "be9b403029c343c5ad44a9831c6f0de0",
            "dd4b6baa3041470e860e60dac6d8a7d4",
            "6e8ffec1fba546c1b26a72a439a9c1a7",
            "c4739e856c3942d9b73f66854fa4f5ee",
            "3f8c0d02a7b74433b78ec0f949d5781f",
            "8bc4cfca68ba4478b257a32b55b3c3fd",
            "3e3ed58dcf434d549cd4aaf506255571",
            "dbe9f26c88104e5b8468effb40a1e9bf",
            "f6b610ff348d4f74b6faac876afbf91b",
            "10d956ff77d34251ba1e7ec595a761f5",
            "ca31d2b9b11f4445b5b4aab11928b8d2",
            "ee0a805639c541feb2a85d12b945b65d",
            "746515aad8b244fc8fa55df452a6b66b",
            "ea12643ceec044d09a242761f3479785",
            "644cad33c98d479d8d211d2111c60e84",
            "794b10b7da634cf49e19c109989efa97",
            "1347cfc7140b452d9ac5883a36536d58",
            "b199a1be75304faf918a5775b1fc44f4",
            "f13550064dc74cd6879071a665582ec5",
            "1f126e26f780436c8b38c321e87c32ad",
            "76c3e1f8fe9043dda6b8185551b25255",
            "1b95d76750954cd1bcd24ac611ebfda5",
            "799d32fa867a46f9b1bb3132db64f6b4",
            "029846359d894569af3f960cbc15977f",
            "e8c3c9f5c5e1475d862a2c1e6914a844",
            "0ec64774e59743a4b03ae242ae8b4fcc",
            "8506f6ede5d5433ab0e9de730f2b4b60",
            "e178ea239cde4440b758ab0656b5895a",
            "d721778a8d314e6fa2a086055131e54f",
            "9ebe9a19660743f188f0f35b4be16037",
            "a3837e1cb19241c29c9ed21bec7ad3a2",
            "945941a32bf84dd3a034273dc0c1ef93"
          ]
        },
        "outputId": "b86b62b5-b7cf-4b07-e450-083df8a62515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Carregando modelo: neuralmind/bert-base-portuguese-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c9d5e0d68b540c6bc6439d7c15d9d85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea99a78afa89473aa3f07914bc6c15ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef044e7d7641462f86d64d3f6a1edca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8372d10e215430db6281169984a5034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca31d2b9b11f4445b5b4aab11928b8d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b95d76750954cd1bcd24ac611ebfda5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dados de treinamento: 160\n",
            "Dados de valida√ß√£o: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar datasets e dataloaders\n",
        "train_dataset = ComentariosDataset(\n",
        "    train_texts,\n",
        "    train_labels,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "val_dataset = ComentariosDataset(\n",
        "    val_texts,\n",
        "    val_labels,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "u27ZGHUtIPUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar o modelo\n",
        "model = SentimentoClassificador(bert_model)\n",
        "model = model.to(device)\n",
        "\n",
        "# Configurar otimizador e scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 10  # 5 √©pocas\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)"
      ],
      "metadata": {
        "id": "zuHFk4QgIPRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de treinamento\n",
        "def treinar_modelo(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs=10):\n",
        "    criterio = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Para acompanhar m√©tricas\n",
        "    historico = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    # Loop de treinamento\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        # Treinamento\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['sentimento'].to(device)\n",
        "\n",
        "            # Zerar gradientes\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Atualizar par√¢metros\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calcular loss m√©dia de treinamento\n",
        "        avg_train_loss = running_loss / len(train_dataloader)\n",
        "        historico['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        print(f\"Perda de treinamento: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Valida√ß√£o\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        todas_predicoes = []\n",
        "        todas_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['sentimento'].to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                loss = criterio(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Obter previs√µes\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "                todas_predicoes.extend(preds.cpu().tolist())\n",
        "                todas_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Calcular m√©tricas\n",
        "        avg_val_loss = running_loss / len(val_dataloader)\n",
        "        accuracy = accuracy_score(todas_labels, todas_predicoes)\n",
        "\n",
        "        historico['val_loss'].append(avg_val_loss)\n",
        "        historico['val_accuracy'].append(accuracy)\n",
        "\n",
        "        print(f\"Perda de valida√ß√£o: {avg_val_loss:.4f}\")\n",
        "        print(f\"Acur√°cia de valida√ß√£o: {accuracy:.4f}\")\n",
        "\n",
        "        # Relat√≥rio detalhado de classifica√ß√£o\n",
        "        if epoch == epochs - 1:\n",
        "            print(\"\\nRelat√≥rio de classifica√ß√£o:\")\n",
        "            print(classification_report(todas_labels, todas_predicoes,\n",
        "                                       target_names=['Negativo', 'Neutro', 'Positivo']))\n",
        "\n",
        "    return historico, model\n"
      ],
      "metadata": {
        "id": "e9zmNKRBIPO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "print(\"\\nIniciando treinamento...\")\n",
        "historico, modelo_treinado = treinar_modelo(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "IU3ljUN4IPL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a778e56e-bafd-4023-ce98-1f2c85297740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando treinamento...\n",
            "\n",
            "Epoch 1/10\n",
            "----------\n",
            "Perda de treinamento: 1.1101\n",
            "Perda de valida√ß√£o: 1.0261\n",
            "Acur√°cia de valida√ß√£o: 0.3750\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "Perda de treinamento: 0.9517\n",
            "Perda de valida√ß√£o: 0.9315\n",
            "Acur√°cia de valida√ß√£o: 0.5500\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "Perda de treinamento: 0.7752\n",
            "Perda de valida√ß√£o: 0.8240\n",
            "Acur√°cia de valida√ß√£o: 0.5750\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "Perda de treinamento: 0.5397\n",
            "Perda de valida√ß√£o: 0.6463\n",
            "Acur√°cia de valida√ß√£o: 0.7250\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "Perda de treinamento: 0.3148\n",
            "Perda de valida√ß√£o: 0.5847\n",
            "Acur√°cia de valida√ß√£o: 0.7000\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "Perda de treinamento: 0.1492\n",
            "Perda de valida√ß√£o: 0.4691\n",
            "Acur√°cia de valida√ß√£o: 0.7750\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "Perda de treinamento: 0.0794\n",
            "Perda de valida√ß√£o: 0.4873\n",
            "Acur√°cia de valida√ß√£o: 0.7500\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "Perda de treinamento: 0.0357\n",
            "Perda de valida√ß√£o: 0.5157\n",
            "Acur√°cia de valida√ß√£o: 0.7750\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "Perda de treinamento: 0.0220\n",
            "Perda de valida√ß√£o: 0.5868\n",
            "Acur√°cia de valida√ß√£o: 0.8000\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "Perda de treinamento: 0.0124\n",
            "Perda de valida√ß√£o: 0.6081\n",
            "Acur√°cia de valida√ß√£o: 0.8000\n",
            "\n",
            "Relat√≥rio de classifica√ß√£o:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.83      0.83      0.83        12\n",
            "      Neutro       1.00      0.64      0.78        14\n",
            "    Positivo       0.68      0.93      0.79        14\n",
            "\n",
            "    accuracy                           0.80        40\n",
            "   macro avg       0.84      0.80      0.80        40\n",
            "weighted avg       0.84      0.80      0.80        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar modelo\n",
        "modelo_path = 'modelo_bertimbau_sentimento.pt'\n",
        "torch.save({\n",
        "    'model_state_dict': modelo_treinado.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'classes': ['Negativo', 'Neutro', 'Positivo']\n",
        "}, modelo_path)\n",
        "\n",
        "print(f\"\\nModelo salvo em: {modelo_path}\")"
      ],
      "metadata": {
        "id": "PlNtfOchIPID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc6179c-a39c-4cb5-b927-160ca8b96f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo salvo em: modelo_bertimbau_sentimento.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para fazer previs√µes em novos dados\n",
        "def prever_sentimento(textos, model, tokenizer, device):\n",
        "    \"\"\"Prever sentimentos para uma lista de textos\"\"\"\n",
        "    model.eval()\n",
        "    resultados = []\n",
        "\n",
        "    for texto in textos:\n",
        "        # Pr√©-processar texto\n",
        "        texto_limpo = limpar_texto(texto)\n",
        "\n",
        "        # Tokenizar\n",
        "        encoding = tokenizer(\n",
        "            texto_limpo,\n",
        "            add_special_tokens=True,\n",
        "            max_length=128,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Preparar tensores\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "        # Predi√ß√£o\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Converter para categoria\n",
        "            sentimento_id = preds.item()\n",
        "            if sentimento_id == 0:\n",
        "                sentimento = \"Negativo\"\n",
        "            elif sentimento_id == 1:\n",
        "                sentimento = \"Neutro\"\n",
        "            else:\n",
        "                sentimento = \"Positivo\"\n",
        "\n",
        "        resultados.append({\n",
        "            'texto': texto,\n",
        "            'sentimento': sentimento,\n",
        "            'sentimento_id': sentimento_id\n",
        "        })\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "xxZKR7lHIPDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previs√µes nos dados n√£o rotulados\n",
        "if len(df_nao_rotulado) > 0:\n",
        "    print(\"\\nRealizando previs√µes nos dados n√£o rotulados...\")\n",
        "\n",
        "    # Criar lotes menores para evitar problemas de mem√≥ria\n",
        "    tamanho_lote = 20\n",
        "    textos_nao_rotulados = df_nao_rotulado['comentario_processado'].values\n",
        "    todas_previsoes = []\n",
        "\n",
        "    for i in range(0, len(textos_nao_rotulados), tamanho_lote):\n",
        "        lote = textos_nao_rotulados[i:i+tamanho_lote]\n",
        "        previsoes_lote = prever_sentimento(lote, modelo_treinado, tokenizer, device)\n",
        "        todas_previsoes.extend(previsoes_lote)\n",
        "\n",
        "    # Criar DataFrame com resultados\n",
        "    resultados = pd.DataFrame(todas_previsoes)\n",
        "\n",
        "    # Juntar com informa√ß√µes originais\n",
        "    df_nao_rotulado.reset_index(inplace=True)\n",
        "\n",
        "    # Verificar se a coluna 'comentario_processado' existe, caso contr√°rio, criar\n",
        "    if 'comentario_processado' not in df_nao_rotulado.columns:\n",
        "        df_nao_rotulado['comentario_processado'] = df_nao_rotulado['comentario'].apply(limpar_texto)\n",
        "\n",
        "    df_resultados = pd.merge(\n",
        "        df_nao_rotulado[['nome', 'comentario', 'comentario_processado']],\n",
        "        resultados[['texto', 'sentimento', 'sentimento_id']],\n",
        "        left_on='comentario_processado',\n",
        "        right_on='texto',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Exibir resultados\n",
        "    print(\"\\nAmostras de previs√µes:\")\n",
        "    print(df_resultados[['nome', 'comentario', 'sentimento']].head(10))\n",
        "\n",
        "    # Salvar resultados\n",
        "    df_resultados.to_csv('resultados_sentimento.csv', index=False)\n",
        "    print(\"\\nResultados salvos em: resultados_sentimento.csv\")"
      ],
      "metadata": {
        "id": "BUh4uc-HIO3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377ddc3b-5f90-4a48-b11c-b321d734f8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Realizando previs√µes nos dados n√£o rotulados...\n",
            "\n",
            "Amostras de previs√µes:\n",
            "            nome                                         comentario sentimento\n",
            "0        Roberto  Um Merlot honesto, dentro do esperado para a s...     Neutro\n",
            "1          Pedro  Simplesmente adorei! Vinho que transmite quali...   Positivo\n",
            "2       Fernanda  Aromas complexos e um paladar refinado. Caminh...   Positivo\n",
            "3          Maria  N√£o achei t√£o especial quanto prometia. N√£o fo...     Neutro\n",
            "4          Sonia  Gostei, mas n√£o achei t√£o especial quanto espe...     Neutro\n",
            "5        Adriano        Aromas apagados e corpo quase inexistente.    Negativo\n",
            "6          Paulo          Caiu muito bem com macarr√£o √† bolonhesa.    Positivo\n",
            "7           Lara             Vai bem pra dias simples, nada demais.     Neutro\n",
            "8      Guilherme   Vale pelo pre√ßo, mas n√£o se destaca no paladar.      Neutro\n",
            "9  Paulo Menezes        Merlot correto, mas sem grandes qualidades.     Neutro\n",
            "\n",
            "Resultados salvos em: resultados_sentimento.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para fazer previs√µes em novos coment√°rios\n",
        "def analisar_novo_comentario(comentario, modelo_treinado, tokenizer, device):\n",
        "    resultados = prever_sentimento([comentario], modelo_treinado, tokenizer, device)\n",
        "    return resultados[0]\n",
        "\n",
        "# Exemplo de uso com novos coment√°rios\n",
        "novos_comentarios = [\n",
        "    \"Este vinho tem um sabor maravilhoso, com notas de frutas vermelhas e um final suave.\",\n",
        "    \"N√£o gostei muito deste vinho, achei o sabor fraco e sem personalidade.\",\n",
        "    \"Um vinho comum, serve para o dia a dia mas n√£o impressiona.\"\n",
        "]\n",
        "\n",
        "print(\"\\nTestando com novos coment√°rios:\")\n",
        "for comentario in novos_comentarios:\n",
        "    resultado = analisar_novo_comentario(comentario, modelo_treinado, tokenizer, device)\n",
        "    print(f\"\\nComent√°rio: {comentario}\")\n",
        "    print(f\"Sentimento: {resultado['sentimento']}\")\n",
        "\n",
        "print(\"\\nAn√°lise de sentimento conclu√≠da com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvhr2qrGEc-R",
        "outputId": "1f34a5aa-b551-4c6f-8447-d60124a56a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando com novos coment√°rios:\n",
            "\n",
            "Coment√°rio: Este vinho tem um sabor maravilhoso, com notas de frutas vermelhas e um final suave.\n",
            "Sentimento: Positivo\n",
            "\n",
            "Coment√°rio: N√£o gostei muito deste vinho, achei o sabor fraco e sem personalidade.\n",
            "Sentimento: Negativo\n",
            "\n",
            "Coment√°rio: Um vinho comum, serve para o dia a dia mas n√£o impressiona.\n",
            "Sentimento: Neutro\n",
            "\n",
            "An√°lise de sentimento conclu√≠da com sucesso!\n"
          ]
        }
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",

  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Análise de Sentimentos com BERTimbau em Comentários de Vinho"
      ],
      "metadata": {
        "id": "5LIUIoGnICG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise de Sentimento usando BERTimbau para textos em português\n",
        "\n",
        "Dataset: 350 linhas com comentários sobre vinho (200 rotuladas)"
      ],
      "metadata": {
        "id": "yBs8wYDuXq6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação das bibliotecas necessárias\n",
        "!pip install transformers pandas numpy scikit-learn torch\n",
        "\n",
        "# Importando as bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92q_JXB3BKzn",
        "outputId": "1da05612-f4fa-4f8f-9a30-c36bbe9f6ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se GPU está disponível\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VgoiZJB1_g",
        "outputId": "01cee2bf-523e-4ff1-c155-98dbea49d49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "try:\n",
        "    # Tente carregar seu dataset real\n",
        "    df = pd.read_csv('/content/drive/MyDrive/datasets/avaliacoes_caminhos_merlot_2023.csv')\n",
        "    print(\"Dataset carregado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"Dataset não carregado! Erro: {e}\")"
      ],
      "metadata": {
        "id": "4xMpnqH8IPok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d4728d-2077-4b1a-fa60-6018a25a2106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar estatísticas do dataset\n",
        "print(\"\\nInformações do Dataset:\")\n",
        "print(f\"Total de registros: {len(df)}\")\n",
        "print(f\"Registros rotulados: {df['sentimento'].notna().sum()}\")\n",
        "print(f\"Registros não rotulados: {df['sentimento'].isna().sum()}\")\n",
        "\n",
        "# Exibir distribuição de sentimentos nos dados rotulados\n",
        "if df['sentimento'].notna().sum() > 0:\n",
        "    sentimentos = df[df['sentimento'].notna()]['sentimento'].value_counts()\n",
        "    print(\"\\nDistribuição de sentimentos:\")\n",
        "    print(f\"Negativos: {sentimentos.get(0, 0)}\")\n",
        "    print(f\"Neutros: {sentimentos.get(1, 0)}\")\n",
        "    print(f\"Positivos: {sentimentos.get(2, 0)}\")\n",
        "\n",
        "# Exibir alguns exemplos\n",
        "print(\"\\nExemplos do dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "d7yKo1bNIPlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c12dbf-a9a0-453c-e301-a20b991c0955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informações do Dataset:\n",
            "Total de registros: 350\n",
            "Registros rotulados: 200\n",
            "Registros não rotulados: 150\n",
            "\n",
            "Distribuição de sentimentos:\n",
            "Negativos: 60\n",
            "Neutros: 70\n",
            "Positivos: 70\n",
            "\n",
            "Exemplos do dataset:\n",
            "       nome                                         comentario  sentimento\n",
            "0   Juliana     Final amargo e desconfortável, não recomendo.          0.0\n",
            "1   Roberto  Um Merlot honesto, dentro do esperado para a s...         NaN\n",
            "2     Pedro  Simplesmente adorei! Vinho que transmite quali...         NaN\n",
            "3  Fernanda  Aromas complexos e um paladar refinado. Caminh...         NaN\n",
            "4       Bia  Infelizmente achei o Caminhos Merlot 2023 muit...         0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento\n",
        "def limpar_texto(texto):\n",
        "    \"\"\"Função para limpar e normalizar o texto\"\"\"\n",
        "    if isinstance(texto, str):\n",
        "        # Converter para minúsculas\n",
        "        texto = texto.lower()\n",
        "        # Remover caracteres especiais, manter acentos\n",
        "        texto = re.sub(r'[^\\w\\s\\dáàâãéèêíìîóòôõúùûçñ]', '', texto)\n",
        "        # Remover espaços extras\n",
        "        texto = re.sub(r'\\s+', ' ', texto)\n",
        "        return texto.strip()\n",
        "    return \"\"\n",
        "\n",
        "# Aplicar limpeza ao dataset completo\n",
        "df['comentario_processado'] = df['comentario'].apply(limpar_texto)"
      ],
      "metadata": {
        "id": "qlIs2FiHIPik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar dados rotulados e não rotulados\n",
        "df_rotulado = df[df['sentimento'].notna()].copy()\n",
        "df_rotulado['sentimento'] = df_rotulado['sentimento'].astype(int)\n",
        "df_nao_rotulado = df[df['sentimento'].isna()].copy()"
      ],
      "metadata": {
        "id": "Hp9VdHj9IPfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe personalizada para o dataset PyTorch\n",
        "class ComentariosDataset(Dataset):\n",
        "    def __init__(self, comentarios, sentimentos, tokenizer, max_len=128):\n",
        "        self.comentarios = comentarios\n",
        "        self.sentimentos = sentimentos\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comentarios)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        comentario = self.comentarios[idx]\n",
        "\n",
        "        # Tokenizar o texto\n",
        "        encoding = self.tokenizer(\n",
        "            comentario,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Converter para tensores e retornar\n",
        "        input_ids = encoding['input_ids'].flatten()\n",
        "        attention_mask = encoding['attention_mask'].flatten()\n",
        "\n",
        "        if self.sentimentos is not None:\n",
        "            sentimento = torch.tensor(self.sentimentos[idx], dtype=torch.long)\n",
        "            return {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask,\n",
        "                'sentimento': sentimento\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': attention_mask\n",
        "            }\n"
      ],
      "metadata": {
        "id": "3EIV4IEVIPc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de classificação baseado no BERTimbau\n",
        "class SentimentoClassificador(torch.nn.Module):\n",
        "    def __init__(self, bert_model, num_classes=3):\n",
        "        super(SentimentoClassificador, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "M7WbwT1tIPaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o tokenizador e modelo BERTimbau\n",
        "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
        "print(f\"\\nCarregando modelo: {model_name}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Divisão dos dados rotulados em treino e validação\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_rotulado['comentario_processado'].values,\n",
        "    df_rotulado['sentimento'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_rotulado['sentimento'].values\n",
        ")\n",
        "\n",
        "print(f\"\\nDados de treinamento: {len(train_texts)}\")\n",
        "print(f\"Dados de validação: {len(val_texts)}\")"
      ],
      "metadata": {
        "id": "YVlY7BezIPXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "6c9d5e0d68b540c6bc6439d7c15d9d85",
            "32dcd6abbf1c4bf992e1f7602dfa6516",
            "e09674d3ed824eea8eb411a1b9790bcb",
            "af08cf88ef96487da8fbaae03fe1df26",
            "a59dd191111c4a19ae6efeed2d030553",
            "df8f948dad9c42f69a2e128252d99397",
            "bd0c5bd422da46f8a1b877f44834675e",
            "7a2a5df4fcf945b588500f7c26ea0f80",
            "faf31186d86e4e12895cb6a1398a3b8d",
            "3cb8733e52d54612a36b8b821cf59f09",
            "91936f0ae9f547c8a49c3eb8e23a9a4f",
            "ea99a78afa89473aa3f07914bc6c15ea",
            "d5a347c1bbc24f41b5b78d37959b4635",
            "d6e536a0bf36431fa7f6c84c456736d7",
            "26d737b59c054a49b8f46ca6a1c63051",
            "3a50e1ef150242e8a04c09d039e196a5",
            "cc247367b16c4507a08d47476bd9e641",
            "26aa5038966b408d9e47707fc5db4a5e",
            "b16c42b3467b4349a3343d4793110847",
            "553cb6b222e24866be781eedce13afca",
            "958f0aabcea644899c93767898fcfceb",
            "8332772143fa4ad1af01eaeb8ff171eb",
            "ef044e7d7641462f86d64d3f6a1edca1",
            "9387554aa1c84b11937c7379e352da28",
            "d278f8741aa4400f8a12346d298cc50a",
            "8358a9aa26c94515b7af6a269a8147a4",
            "c1a52c9bb1d0413e82601937d728afaa",
            "7b0da143ed3e4ebab62b6cfc577d8fbd",
            "cc861bea7c3e4fb18d5359ff9fb60915",
            "1747983b4d1e4870898b3ec69b8d3d07",
            "4f9c57b1c9e64bd79a86e0dcdf392717",
            "1dc315579a274fef8db95aec18f580dd",
            "c74e46dba06e499691c090adf5b222ea",
            "d8372d10e215430db6281169984a5034",
            "be9b403029c343c5ad44a9831c6f0de0",
            "dd4b6baa3041470e860e60dac6d8a7d4",
            "6e8ffec1fba546c1b26a72a439a9c1a7",
            "c4739e856c3942d9b73f66854fa4f5ee",
            "3f8c0d02a7b74433b78ec0f949d5781f",
            "8bc4cfca68ba4478b257a32b55b3c3fd",
            "3e3ed58dcf434d549cd4aaf506255571",
            "dbe9f26c88104e5b8468effb40a1e9bf",
            "f6b610ff348d4f74b6faac876afbf91b",
            "10d956ff77d34251ba1e7ec595a761f5",
            "ca31d2b9b11f4445b5b4aab11928b8d2",
            "ee0a805639c541feb2a85d12b945b65d",
            "746515aad8b244fc8fa55df452a6b66b",
            "ea12643ceec044d09a242761f3479785",
            "644cad33c98d479d8d211d2111c60e84",
            "794b10b7da634cf49e19c109989efa97",
            "1347cfc7140b452d9ac5883a36536d58",
            "b199a1be75304faf918a5775b1fc44f4",
            "f13550064dc74cd6879071a665582ec5",
            "1f126e26f780436c8b38c321e87c32ad",
            "76c3e1f8fe9043dda6b8185551b25255",
            "1b95d76750954cd1bcd24ac611ebfda5",
            "799d32fa867a46f9b1bb3132db64f6b4",
            "029846359d894569af3f960cbc15977f",
            "e8c3c9f5c5e1475d862a2c1e6914a844",
            "0ec64774e59743a4b03ae242ae8b4fcc",
            "8506f6ede5d5433ab0e9de730f2b4b60",
            "e178ea239cde4440b758ab0656b5895a",
            "d721778a8d314e6fa2a086055131e54f",
            "9ebe9a19660743f188f0f35b4be16037",
            "a3837e1cb19241c29c9ed21bec7ad3a2",
            "945941a32bf84dd3a034273dc0c1ef93"
          ]
        },
        "outputId": "b86b62b5-b7cf-4b07-e450-083df8a62515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Carregando modelo: neuralmind/bert-base-portuguese-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c9d5e0d68b540c6bc6439d7c15d9d85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea99a78afa89473aa3f07914bc6c15ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef044e7d7641462f86d64d3f6a1edca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8372d10e215430db6281169984a5034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca31d2b9b11f4445b5b4aab11928b8d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b95d76750954cd1bcd24ac611ebfda5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dados de treinamento: 160\n",
            "Dados de validação: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar datasets e dataloaders\n",
        "train_dataset = ComentariosDataset(\n",
        "    train_texts,\n",
        "    train_labels,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "val_dataset = ComentariosDataset(\n",
        "    val_texts,\n",
        "    val_labels,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "u27ZGHUtIPUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar o modelo\n",
        "model = SentimentoClassificador(bert_model)\n",
        "model = model.to(device)\n",
        "\n",
        "# Configurar otimizador e scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * 10  # 5 épocas\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)"
      ],
      "metadata": {
        "id": "zuHFk4QgIPRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de treinamento\n",
        "def treinar_modelo(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs=10):\n",
        "    criterio = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Para acompanhar métricas\n",
        "    historico = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    # Loop de treinamento\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        # Treinamento\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['sentimento'].to(device)\n",
        "\n",
        "            # Zerar gradientes\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Atualizar parâmetros\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calcular loss média de treinamento\n",
        "        avg_train_loss = running_loss / len(train_dataloader)\n",
        "        historico['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        print(f\"Perda de treinamento: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validação\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        todas_predicoes = []\n",
        "        todas_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['sentimento'].to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                loss = criterio(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Obter previsões\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "                todas_predicoes.extend(preds.cpu().tolist())\n",
        "                todas_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Calcular métricas\n",
        "        avg_val_loss = running_loss / len(val_dataloader)\n",
        "        accuracy = accuracy_score(todas_labels, todas_predicoes)\n",
        "\n",
        "        historico['val_loss'].append(avg_val_loss)\n",
        "        historico['val_accuracy'].append(accuracy)\n",
        "\n",
        "        print(f\"Perda de validação: {avg_val_loss:.4f}\")\n",
        "        print(f\"Acurácia de validação: {accuracy:.4f}\")\n",
        "\n",
        "        # Relatório detalhado de classificação\n",
        "        if epoch == epochs - 1:\n",
        "            print(\"\\nRelatório de classificação:\")\n",
        "            print(classification_report(todas_labels, todas_predicoes,\n",
        "                                       target_names=['Negativo', 'Neutro', 'Positivo']))\n",
        "\n",
        "    return historico, model\n"
      ],
      "metadata": {
        "id": "e9zmNKRBIPO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "print(\"\\nIniciando treinamento...\")\n",
        "historico, modelo_treinado = treinar_modelo(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "IU3ljUN4IPL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a778e56e-bafd-4023-ce98-1f2c85297740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando treinamento...\n",
            "\n",
            "Epoch 1/10\n",
            "----------\n",
            "Perda de treinamento: 1.1101\n",
            "Perda de validação: 1.0261\n",
            "Acurácia de validação: 0.3750\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "Perda de treinamento: 0.9517\n",
            "Perda de validação: 0.9315\n",
            "Acurácia de validação: 0.5500\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "Perda de treinamento: 0.7752\n",
            "Perda de validação: 0.8240\n",
            "Acurácia de validação: 0.5750\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "Perda de treinamento: 0.5397\n",
            "Perda de validação: 0.6463\n",
            "Acurácia de validação: 0.7250\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "Perda de treinamento: 0.3148\n",
            "Perda de validação: 0.5847\n",
            "Acurácia de validação: 0.7000\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "Perda de treinamento: 0.1492\n",
            "Perda de validação: 0.4691\n",
            "Acurácia de validação: 0.7750\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "Perda de treinamento: 0.0794\n",
            "Perda de validação: 0.4873\n",
            "Acurácia de validação: 0.7500\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "Perda de treinamento: 0.0357\n",
            "Perda de validação: 0.5157\n",
            "Acurácia de validação: 0.7750\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "Perda de treinamento: 0.0220\n",
            "Perda de validação: 0.5868\n",
            "Acurácia de validação: 0.8000\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "Perda de treinamento: 0.0124\n",
            "Perda de validação: 0.6081\n",
            "Acurácia de validação: 0.8000\n",
            "\n",
            "Relatório de classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.83      0.83      0.83        12\n",
            "      Neutro       1.00      0.64      0.78        14\n",
            "    Positivo       0.68      0.93      0.79        14\n",
            "\n",
            "    accuracy                           0.80        40\n",
            "   macro avg       0.84      0.80      0.80        40\n",
            "weighted avg       0.84      0.80      0.80        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar modelo\n",
        "modelo_path = 'modelo_bertimbau_sentimento.pt'\n",
        "torch.save({\n",
        "    'model_state_dict': modelo_treinado.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'classes': ['Negativo', 'Neutro', 'Positivo']\n",
        "}, modelo_path)\n",
        "\n",
        "print(f\"\\nModelo salvo em: {modelo_path}\")"
      ],
      "metadata": {
        "id": "PlNtfOchIPID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc6179c-a39c-4cb5-b927-160ca8b96f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo salvo em: modelo_bertimbau_sentimento.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para fazer previsões em novos dados\n",
        "def prever_sentimento(textos, model, tokenizer, device):\n",
        "    \"\"\"Prever sentimentos para uma lista de textos\"\"\"\n",
        "    model.eval()\n",
        "    resultados = []\n",
        "\n",
        "    for texto in textos:\n",
        "        # Pré-processar texto\n",
        "        texto_limpo = limpar_texto(texto)\n",
        "\n",
        "        # Tokenizar\n",
        "        encoding = tokenizer(\n",
        "            texto_limpo,\n",
        "            add_special_tokens=True,\n",
        "            max_length=128,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Preparar tensores\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "        # Predição\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Converter para categoria\n",
        "            sentimento_id = preds.item()\n",
        "            if sentimento_id == 0:\n",
        "                sentimento = \"Negativo\"\n",
        "            elif sentimento_id == 1:\n",
        "                sentimento = \"Neutro\"\n",
        "            else:\n",
        "                sentimento = \"Positivo\"\n",
        "\n",
        "        resultados.append({\n",
        "            'texto': texto,\n",
        "            'sentimento': sentimento,\n",
        "            'sentimento_id': sentimento_id\n",
        "        })\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "xxZKR7lHIPDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões nos dados não rotulados\n",
        "if len(df_nao_rotulado) > 0:\n",
        "    print(\"\\nRealizando previsões nos dados não rotulados...\")\n",
        "\n",
        "    # Criar lotes menores para evitar problemas de memória\n",
        "    tamanho_lote = 20\n",
        "    textos_nao_rotulados = df_nao_rotulado['comentario_processado'].values\n",
        "    todas_previsoes = []\n",
        "\n",
        "    for i in range(0, len(textos_nao_rotulados), tamanho_lote):\n",
        "        lote = textos_nao_rotulados[i:i+tamanho_lote]\n",
        "        previsoes_lote = prever_sentimento(lote, modelo_treinado, tokenizer, device)\n",
        "        todas_previsoes.extend(previsoes_lote)\n",
        "\n",
        "    # Criar DataFrame com resultados\n",
        "    resultados = pd.DataFrame(todas_previsoes)\n",
        "\n",
        "    # Juntar com informações originais\n",
        "    df_nao_rotulado.reset_index(inplace=True)\n",
        "\n",
        "    # Verificar se a coluna 'comentario_processado' existe, caso contrário, criar\n",
        "    if 'comentario_processado' not in df_nao_rotulado.columns:\n",
        "        df_nao_rotulado['comentario_processado'] = df_nao_rotulado['comentario'].apply(limpar_texto)\n",
        "\n",
        "    df_resultados = pd.merge(\n",
        "        df_nao_rotulado[['nome', 'comentario', 'comentario_processado']],\n",
        "        resultados[['texto', 'sentimento', 'sentimento_id']],\n",
        "        left_on='comentario_processado',\n",
        "        right_on='texto',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Exibir resultados\n",
        "    print(\"\\nAmostras de previsões:\")\n",
        "    print(df_resultados[['nome', 'comentario', 'sentimento']].head(10))\n",
        "\n",
        "    # Salvar resultados\n",
        "    df_resultados.to_csv('resultados_sentimento.csv', index=False)\n",
        "    print(\"\\nResultados salvos em: resultados_sentimento.csv\")"
      ],
      "metadata": {
        "id": "BUh4uc-HIO3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377ddc3b-5f90-4a48-b11c-b321d734f8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Realizando previsões nos dados não rotulados...\n",
            "\n",
            "Amostras de previsões:\n",
            "            nome                                         comentario sentimento\n",
            "0        Roberto  Um Merlot honesto, dentro do esperado para a s...     Neutro\n",
            "1          Pedro  Simplesmente adorei! Vinho que transmite quali...   Positivo\n",
            "2       Fernanda  Aromas complexos e um paladar refinado. Caminh...   Positivo\n",
            "3          Maria  Não achei tão especial quanto prometia. Não fo...     Neutro\n",
            "4          Sonia  Gostei, mas não achei tão especial quanto espe...     Neutro\n",
            "5        Adriano        Aromas apagados e corpo quase inexistente.    Negativo\n",
            "6          Paulo          Caiu muito bem com macarrão à bolonhesa.    Positivo\n",
            "7           Lara             Vai bem pra dias simples, nada demais.     Neutro\n",
            "8      Guilherme   Vale pelo preço, mas não se destaca no paladar.      Neutro\n",
            "9  Paulo Menezes        Merlot correto, mas sem grandes qualidades.     Neutro\n",
            "\n",
            "Resultados salvos em: resultados_sentimento.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para fazer previsões em novos comentários\n",
        "def analisar_novo_comentario(comentario, modelo_treinado, tokenizer, device):\n",
        "    resultados = prever_sentimento([comentario], modelo_treinado, tokenizer, device)\n",
        "    return resultados[0]\n",
        "\n",
        "# Exemplo de uso com novos comentários\n",
        "novos_comentarios = [\n",
        "    \"Este vinho tem um sabor maravilhoso, com notas de frutas vermelhas e um final suave.\",\n",
        "    \"Não gostei muito deste vinho, achei o sabor fraco e sem personalidade.\",\n",
        "    \"Um vinho comum, serve para o dia a dia mas não impressiona.\"\n",
        "]\n",
        "\n",
        "print(\"\\nTestando com novos comentários:\")\n",
        "for comentario in novos_comentarios:\n",
        "    resultado = analisar_novo_comentario(comentario, modelo_treinado, tokenizer, device)\n",
        "    print(f\"\\nComentário: {comentario}\")\n",
        "    print(f\"Sentimento: {resultado['sentimento']}\")\n",
        "\n",
        "print(\"\\nAnálise de sentimento concluída com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvhr2qrGEc-R",
        "outputId": "1f34a5aa-b551-4c6f-8447-d60124a56a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando com novos comentários:\n",
            "\n",
            "Comentário: Este vinho tem um sabor maravilhoso, com notas de frutas vermelhas e um final suave.\n",
            "Sentimento: Positivo\n",
            "\n",
            "Comentário: Não gostei muito deste vinho, achei o sabor fraco e sem personalidade.\n",
            "Sentimento: Negativo\n",
            "\n",
            "Comentário: Um vinho comum, serve para o dia a dia mas não impressiona.\n",
            "Sentimento: Neutro\n",
            "\n",
            "Análise de sentimento concluída com sucesso!\n"
          ]
        }
      ]
    }
  ]
}
